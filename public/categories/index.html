<!DOCTYPE html>
<html lang="en-us">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Alejandro Paredes La Torre</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="">
    <meta name="generator" content="Hugo 0.151.2">
    
    
    
      <meta name="robots" content="noindex, nofollow">
    
    

    
<link rel="stylesheet" href="/ananke/css/main.min.css" >




    


    
      

    

    
    
      <link href="/categories/index.xml" rel="alternate" type="application/rss+xml" title="Alejandro Paredes La Torre" />
      <link href="/categories/index.xml" rel="feed" type="application/rss+xml" title="Alejandro Paredes La Torre" />
      
    

    
      <link rel="canonical" href="http://localhost:1313/categories/">
    

    <meta property="og:url" content="http://localhost:1313/categories/">
  <meta property="og:site_name" content="Alejandro Paredes La Torre">
  <meta property="og:title" content="Categories">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="website">

  <meta itemprop="name" content="Categories">
  <meta itemprop="datePublished" content="2025-10-19T00:00:00+00:00">
  <meta itemprop="dateModified" content="2025-10-19T00:00:00+00:00">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Categories">

	
  </head><body class="ma0 avenir bg-near-white development">

    

  <header>
    <div class="pb3-m pb6-l bg-black">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l center items-center justify-between">
    <a href="/" class="f3 fw2 hover-white white-90 dib no-underline">
      
        Alejandro Paredes La Torre
      
    </a>
    <div class="flex-l items-center">
      

      
      <div class="ananke-socials"></div>

    </div>
  </div>
</nav>

      <div class="tc-l pv3 ph3 ph4-ns">
        <h1 class="f2 f-subheadline-l fw2 light-silver mb0 lh-title">
          Categories
        </h1>
        
      </div>
    </div>
  </header>


    <main class="pb7" role="main">
      
    
  <article class="cf pa3 pa4-m pa4-l">
    <div class="measure-wide-l center f4 lh-copy nested-copy-line-height nested-links mid-gray">
      
    </div>
  </article>
  <div class="mw8 center">
    <section class="ph4">
      
        <h2 class="f1">
          <a href="/categories/ai--ml/" class="link blue hover-black">
            Category: AI &amp; ML
          </a>
        </h2>
        
          <div class="w-100 mb4 nested-copy-line-height relative bg-white">
  <div class="mb3 pa4 gray overflow-hidden bg-white">
    <span class="f6 db">Posts</span>
    <h1 class="f3 near-black">
      <a href="/posts/shapely-values/" class="link black dim">
        Understanding SHAP Values: From Theory to Implementation
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      <p><img src="pizza_shapley_story.gif" alt="Pizza Shapley Animation"></p>
<blockquote>
<p><strong>TL;DR</strong> — SHAP (SHapley Additive exPlanations) is a principled framework for interpreting ML predictions. By borrowing ideas from cooperative game theory, SHAP quantifies the contribution of each feature for a given prediction. In this guide, we’ll unpack the math, intuition, and practical implementation.</p>
</blockquote>
<hr>
<h2 id="1-motivation--why-interpretability-matters">1. Motivation — Why Interpretability Matters</h2>
<p>Modern machine learning models are increasingly complex, think ensembles, gradient boosting, or deep neural networks. Without interpretability, these models are <strong>black boxes</strong>. Understanding <em>why</em> a model makes a prediction is essential for:</p>
    </div>
    <a href="/posts/shapely-values/" class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a>
  </div>
</div>

        
      
        <h2 class="f1">
          <a href="/categories/explainable-ai/" class="link blue hover-black">
            Category: Explainable AI
          </a>
        </h2>
        
          <div class="w-100 mb4 nested-copy-line-height relative bg-white">
  <div class="mb3 pa4 gray overflow-hidden bg-white">
    <span class="f6 db">Posts</span>
    <h1 class="f3 near-black">
      <a href="/posts/shapely-values/" class="link black dim">
        Understanding SHAP Values: From Theory to Implementation
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      <p><img src="pizza_shapley_story.gif" alt="Pizza Shapley Animation"></p>
<blockquote>
<p><strong>TL;DR</strong> — SHAP (SHapley Additive exPlanations) is a principled framework for interpreting ML predictions. By borrowing ideas from cooperative game theory, SHAP quantifies the contribution of each feature for a given prediction. In this guide, we’ll unpack the math, intuition, and practical implementation.</p>
</blockquote>
<hr>
<h2 id="1-motivation--why-interpretability-matters">1. Motivation — Why Interpretability Matters</h2>
<p>Modern machine learning models are increasingly complex, think ensembles, gradient boosting, or deep neural networks. Without interpretability, these models are <strong>black boxes</strong>. Understanding <em>why</em> a model makes a prediction is essential for:</p>
    </div>
    <a href="/posts/shapely-values/" class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a>
  </div>
</div>

        
      
    </section>
  </div>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white white-70 dn dib-ns pv2 ph3 no-underline" href="http://localhost:1313/" >
    &copy;  Alejandro Paredes La Torre 2025 
  </a>
    <div><div class="ananke-socials"></div>
</div>
  </div>
</footer>

  </body>
</html>
